{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huggingface SageMaker-SDK - BERT Japanese QA example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Introduction](#Introduction)  \n",
    "2. [Development Environment and Permissions](#Development-Environment-and-Permissions)\n",
    "    1. [Installation](#Installation)  \n",
    "    2. [Permissions](#Permissions)\n",
    "    3. [Uploading data to sagemaker_session_bucket](#Uploading-data-to-sagemaker_session_bucket)  \n",
    "3. [(Optional) Deepen your understanding of SQuAD](#(Optional)-Deepen-your-understanding-of-SQuAD)    \n",
    "4. [Fine-tuning & starting Sagemaker Training Job](#Fine-tuning-\\&-starting-Sagemaker-Training-Job)  \n",
    "    1. [Creating an Estimator and start a training job](#Creating-an-Estimator-and-start-a-training-job)  \n",
    "    2. [Estimator Parameters](#Estimator-Parameters)   \n",
    "    3. [Download fine-tuned model from s3](#Download-fine-tuned-model-from-s3)\n",
    "    4. [Question Answering on Local](#Question-Answering-on-Local)  \n",
    "5. [_Coming soon_:Push model to the Hugging Face hub](#Push-model-to-the-Hugging-Face-hub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "このnotebookはHuggingFaceの[run_squad.py](https://github.com/huggingface/transformers/blob/master/examples/legacy/question-answering/run_squad.py)を日本語データで動作する様に変更を加えたものです。    \n",
    "データは[運転ドメインQAデータセット](https://nlp.ist.i.kyoto-u.ac.jp/index.php?Driving%20domain%20QA%20datasets)を使用します。    \n",
    "\n",
    "このデモでは、AmazonSageMakerのHuggingFace Estimatorを使用してSageMakerのトレーニングジョブを実行します。    \n",
    "\n",
    "_**NOTE: このデモは、SagemakerNotebookインスタンスで動作検証しています**_    \n",
    "    _**データセットは各自許諾に同意の上ダウンロードしていただけますようお願いいたします（データサイズは約4MBです）**_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development Environment and Permissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "このNotebookはSageMakerの`conda_pytorch_p36`カーネルを利用しています。    \n",
    "日本語処理のため、`transformers`ではなく`transformers[ja]`をインスールします。\n",
    "\n",
    "**_Note: このnotebook上で推論テストを行う場合、（バージョンが古い場合は）pytorchのバージョンアップが必要になります。_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# localで推論のテストを行う場合\n",
    "!pip install torch==1.7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install \"sagemaker>=2.31.0\" \"transformers[ja]==4.6.1\" \"datasets[s3]==1.6.2\" --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ローカル環境でSagemakerを使用する場合はSagemakerに必要な権限を持つIAMロールにアクセスする必要があります。[こちら](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html)を参照してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データの準備\n",
    "\n",
    "事前にデータ(`DDQA-1.0.tar.gz`)をこのnotobookと同じ階層に配置してください\n",
    "\n",
    "以下では、データをダウンロードして解凍 (unzip) します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip\n",
    "\n",
    "!tar -zxvf DDQA-1.0.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading data to `sagemaker_session_bucket`\n",
    "\n",
    "S3へデータをアップロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_prefix = 'samples/datasets/driving-domain-qa'\n",
    "\n",
    "input_train = sess.upload_data(\n",
    "    path='./DDQA-1.0/RC-QA/DDQA-1.0_RC-QA_train.json', \n",
    "    key_prefix=f'{s3_prefix}/train'\n",
    ")\n",
    "\n",
    "input_validation = sess.upload_data(\n",
    "    path='./DDQA-1.0/RC-QA/DDQA-1.0_RC-QA_dev.json', \n",
    "    key_prefix=f'{s3_prefix}/valid'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データのUpload path\n",
    "\n",
    "print(input_train)\n",
    "print(input_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Deepen your understanding of SQuAD\n",
    "\n",
    "**このセクションはオプションであり、Fine-tuning & starting Sagemaker Training Jobまでスキップできます**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 運転ドメインQAデータセットについて\n",
    "\n",
    "運転ドメインQAデータセットはSQuAD2.0形式となっており、`run_squad.py`でそのまま実行できます。    \n",
    "トレーニングジョブの実行とは関連しませんが、ここでは少しデータについて理解を深めたいと思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QAデータセットの形式(README_ja.txt)\n",
    "--------------------\n",
    "\n",
    "本QAデータセットの形式はSQuAD2.0と同じです。SQuAD2.0の問題は、「文章」、「質問」、「答え」の三つ組になっており、「答え」は「文章」の中の一部になっています。一部の問題は、「文章」の中に「答え」が無いなど、答えられない問題になっています。詳細は以下の論文をご参照ください。\n",
    "\n",
    "Pranav Rajpurkar, Robin Jia, and Percy Liang.\n",
    "Know what you don’t know: Unanswerable questions for SQuAD,\n",
    "In ACL2018, pages 784–789.\n",
    "https://www.aclweb.org/anthology/P18-2124.pdf\n",
    "\n",
    "以下に、jsonファイル中のQAデータセットを例示します。    \n",
    "注）jsonファイル中の\"context\"は「文章」\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"version\": \"v2.0\",\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"title\": \"運転ドメイン\",\n",
    "            \"paragraphs\": [\n",
    "                {\n",
    "                    \"context\": \"著者は以下の文章を書きました。本日お昼頃、梅田方面へ自転車で出かけました。ちょっと大きな交差点に差し掛かりました。自転車にまたがった若い女性が信号待ちしています。その後で私も止まって信号が青になるのを待っていました。\",\n",
    "                    \"qas\": [\n",
    "                        {\n",
    "                            \"id\": \"55604556390008_00\",\n",
    "                            \"question\": \"待っていました、の主語は何か？\",\n",
    "                            \"answers\": [\n",
    "                                {\n",
    "                                    \"text\": \"私\",\n",
    "                                    \"answer_start\": 85\n",
    "                                },\n",
    "                                {\n",
    "                                    \"text\": \"著者\",\n",
    "                                    \"answer_start\": 0\n",
    "                                }\n",
    "                            ],\n",
    "                            \"is_impossible\": false\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "参考文献\n",
    "--------\n",
    "\n",
    "高橋 憲生、柴田 知秀、河原 大輔、黒橋 禎夫\n",
    "ドメインを限定した機械読解モデルに基づく述語項構造解析\n",
    "言語処理学会 第25回年次大会 発表論文集 (2019年3月)\n",
    "　https://www.anlp.jp/proceedings/annual_meeting/2019/pdf_dir/B1-4.pdf    \n",
    "　　※データセットの構築方法について記載\n",
    "\n",
    "Norio Takahashi, Tomohide Shibata, Daisuke Kawahara and Sadao Kurohashi.\n",
    "Machine Comprehension Improves Domain-Specific Japanese Predicate-Argument Structure Analysis,\n",
    "In Proceedings of 2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing, Workshop MRQA: Machine Reading for Question Answering, 2019.\n",
    "　https://mrqa.github.io/assets/papers/42_Paper.pdf    \n",
    "　　※データセットの構築方法、文章中に答えが無い問題について記載"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "import json\n",
    "\n",
    "with open(\"./DDQA-1.0/RC-QA/DDQA-1.0_RC-QA_train.json\", \"r\") as f:\n",
    "    squad = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad['data'][0]['paragraphs'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQuAD2.0形式は少し複雑なjson形式となっています。    \n",
    "次に`run_squad.py`内でどのような前処理が実行されているかについて少し触れます。    \n",
    "\n",
    "このparagraphsにはコンテキストが1つと質問が2つ、回答が6つ含まれていますが、後の処理ではここから    \n",
    "**2つの「コンテキスト」、「質問」、「答え」の三つ組**が作成されます。    \n",
    "回答は1番目のものが使用されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.data.processors.squad import SquadV2Processor\n",
    "from transformers import squad_convert_examples_to_features\n",
    "\n",
    "data_dir = './DDQA-1.0/RC-QA'\n",
    "train_file = 'DDQA-1.0_RC-QA_train.json'\n",
    "\n",
    "max_seq_length = 384 # トークン化後の最大入力シーケンス長。これより長いシーケンスは切り捨てられ、これより短いシーケンスはパディングされます\n",
    "doc_stride = 128 # 長いドキュメントをチャンクに分割する場合、チャンク間でどのくらいのストライドを取るか\n",
    "max_query_length = 64 # 質問のトークンの最大数。 これより長い質問はこの長さに切り捨てられます\n",
    "threads = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jsonファイルを読みこみ、複雑な構造を分解します\n",
    "\n",
    "processor = SquadV2Processor()\n",
    "examples = processor.get_train_examples(data_dir, filename=train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QuestionAnsweringモデルへ入力できるようにトークナイズします\n",
    "# 以下の実行に数分時間がかかります\n",
    "\n",
    "features, dataset = squad_convert_examples_to_features(\n",
    "    examples=examples,\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=max_seq_length,\n",
    "    doc_stride=doc_stride,\n",
    "    max_query_length=max_query_length,\n",
    "    is_training=True,\n",
    "    return_dataset=\"pt\",\n",
    "    threads=threads,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dataset`は後に`dataloader`に渡され、以下のように使用されます。\n",
    "\n",
    "\n",
    "```python\n",
    "for _ in train_iterator:\n",
    "    epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])\n",
    "    for step, batch in enumerate(epoch_iterator):\n",
    "\n",
    "        # Skip past any already trained steps if resuming training\n",
    "        if steps_trained_in_current_epoch > 0:\n",
    "            steps_trained_in_current_epoch -= 1\n",
    "            continue\n",
    "\n",
    "        model.train()\n",
    "        batch = tuple(t.to(args.device) for t in batch)\n",
    "\n",
    "        inputs = {\n",
    "            \"input_ids\": batch[0],\n",
    "            \"attention_mask\": batch[1],\n",
    "            \"token_type_ids\": batch[2],\n",
    "            \"start_positions\": batch[3],\n",
    "            \"end_positions\": batch[4],\n",
    "        }\n",
    "```\n",
    "\n",
    "`input_ids`, `attention_mask`, `token_type_ids`はTransformerベースのモデルで一般的な入力形式です    \n",
    "QuestionAnsweringモデル特有のものとして`start_positions`, `end_positions`が挙げられます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 参考に一つ目の中身を見てみます\n",
    "\n",
    "i = 0\n",
    "dataset[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# すでに テキスト→トークン化→ID化されているため、逆の操作で元に戻します。\n",
    "# 質問と文章が含まれていることが確認できます\n",
    "\n",
    "tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(dataset[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID化→トークン化まで\n",
    "\n",
    "tokenizer.convert_ids_to_tokens(dataset[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 回答は、start_positionsのトークンで始まり、end_positionsでトークンで終わるように表現されます\n",
    "# 試しに該当箇所のトークンを文字に戻してみます。\n",
    "\n",
    "print(tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens([dataset[i][0][dataset[i][3]]])))\n",
    "print(tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens([dataset[i][0][dataset[i][4]]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これから実行する`QuestionAnswering`は、**「コンテキスト」**内から**「質問」**に対する**「答え」**となる`start_positions`と`end_positions`を予測し、そのスパンを抽出するタスクとなります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning & starting Sagemaker Training Job\n",
    "\n",
    "`HuggingFace`のトレーニングジョブを作成するためには`HuggingFace` Estimatorが必要になります。    \n",
    "Estimatorは、エンドツーエンドのAmazonSageMakerトレーニングおよびデプロイタスクを処理します。 Estimatorで、どのFine-tuningスクリプトを`entry_point`として使用するか、どの`instance_type`を使用するか、どの`hyperparameters`を渡すかなどを定義します。\n",
    "\n",
    "\n",
    "```python\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point='train.py',\n",
    "    source_dir='./scripts',\n",
    "    base_job_name='huggingface-sdk-extension',\n",
    "    instance_type='ml.p3.2xlarge',\n",
    "    instance_count=1,\n",
    "    transformers_version='4.4',\n",
    "    pytorch_version='1.6',\n",
    "    py_version='py36',\n",
    "    role=role,\n",
    "    hyperparameters={\n",
    "        'epochs': 1,\n",
    "        'train_batch_size': 32,\n",
    "        'model_name':'distilbert-base-uncased'\n",
    "    }\n",
    ")\n",
    "```\n",
    "\n",
    "SageMakerトレーニングジョブを作成すると、SageMakerは`huggingface`コンテナを実行するために必要なec2インスタンスの起動と管理を行います。    \n",
    "Fine-tuningスクリプト`train.py`をアップロードし、`sagemaker_session_bucket`からコンテナ内の`/opt/ml/input/data`にデータをダウンロードして、トレーニングジョブを実行します。\n",
    "\n",
    "\n",
    "```python\n",
    "/opt/conda/bin/python train.py --epochs 1 --model_name distilbert-base-uncased --train_batch_size 32\n",
    "```\n",
    "\n",
    "`HuggingFace estimator`で定義した`hyperparameters`は、名前付き引数として渡されます。\n",
    "\n",
    "またSagemakerは、次のようなさまざまな環境変数を通じて、トレーニング環境に関する有用なプロパティを提供しています。\n",
    "\n",
    "* `SM_MODEL_DIR`：トレーニングジョブがモデルアーティファクトを書き込むパスを表す文字列。トレーニング後、このディレクトリのアーティファクトはモデルホスティングのためにS3にアップロードされます。\n",
    "\n",
    "* `SM_NUM_GPUS`：ホストで使用可能なGPUの数を表す整数。\n",
    "\n",
    "* `SM_CHANNEL_XXXX`：指定されたチャネルの入力データを含むディレクトリへのパスを表す文字列。たとえば、HuggingFace estimatorのfit呼び出しで`train`と`test`という名前の2つの入力チャネルを指定すると、環境変数`SM_CHANNEL_TRAIN`と`SM_CHANNEL_TEST`が設定されます。\n",
    "\n",
    "このトレーニングジョブをローカル環境で実行するには、`instance_type='local'`、GPUの場合は`instance_type='local-gpu'`で定義できます。    \n",
    "**_Note：これはSageMaker Studio内では機能しません_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements.txtはトレーニングジョブの実行前に実行されます（コンテナにライブラリを追加する際に使用します）\n",
    "# 残念なことにSageMakerのHuggingFaceコンテナは日本語処理（トークナイズ）に必要なライブラリが組み込まれていません\n",
    "# したがってtransformers[ja]==4.6.1をジョブ実行前にインストールしています（fugashiとipadic）でも構いません\n",
    "# tensorboardも組み込まれていないため、インストールします\n",
    "\n",
    "!pygmentize ./scripts/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーニングジョブで実行されるコード\n",
    "!pygmentize ./scripts/run_squad.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters={\n",
    "    'model_type': 'bert',\n",
    "    'model_name_or_path': 'cl-tohoku/bert-base-japanese-whole-word-masking',\n",
    "    'output_dir': '/opt/ml/model',\n",
    "    'data_dir':'/opt/ml/input/data',\n",
    "    'train_file': 'train/DDQA-1.0_RC-QA_train.json',\n",
    "    'predict_file': 'validation/DDQA-1.0_RC-QA_dev.json',\n",
    "    'version_2_with_negative': 'True',\n",
    "    'do_train': 'True',\n",
    "    'do_eval': 'True',\n",
    "    'fp16': 'True',\n",
    "    'per_gpu_train_batch_size': 16,\n",
    "    'per_gpu_eval_batch_size': 16,\n",
    "    'max_seq_length': 384,\n",
    "    'doc_stride': 128,\n",
    "    'max_query_length': 64,\n",
    "    'learning_rate': 5e-5,\n",
    "    'num_train_epochs': 2,\n",
    "    #'max_steps': 100, # If > 0: set total number of training steps to perform. Override num_train_epochs.\n",
    "    'save_steps': 1000, \n",
    "}\n",
    "\n",
    "# metric definition to extract the results\n",
    "metric_definitions=[\n",
    "     {\"Name\": \"train_runtime\", \"Regex\": \"train_runtime.*=\\D*(.*?)$\"},\n",
    "     {'Name': 'train_samples_per_second', 'Regex': \"train_samples_per_second.*=\\D*(.*?)$\"},\n",
    "     {'Name': 'epoch', 'Regex': \"epoch.*=\\D*(.*?)$\"},\n",
    "     {'Name': 'f1', 'Regex': \"f1.*=\\D*(.*?)$\"},\n",
    "     {'Name': 'exact_match', 'Regex': \"exact_match.*=\\D*(.*?)$\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Estimator and start a training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator\n",
    "\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point='run_squad.py',\n",
    "    source_dir='./scripts',\n",
    "    metric_definitions=metric_definitions,\n",
    "    instance_type='ml.p3.8xlarge',\n",
    "    instance_count=1,\n",
    "    volume_size=200,\n",
    "    role=role,\n",
    "    transformers_version='4.6',\n",
    "    pytorch_version='1.7',\n",
    "    py_version='py36',\n",
    "    hyperparameters=hyperparameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting the train job with our uploaded datasets as input\n",
    "huggingface_estimator.fit({'train': input_train, 'validation': input_validation})\n",
    "\n",
    "# ml.p3.8xlarge, 2 epochでの実行時間の目安\n",
    "# Training seconds: 758\n",
    "# Billable seconds: 758"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# container image used for training job\n",
    "print(f\"container image used for training job: \\n{huggingface_estimator.image_uri}\\n\")\n",
    "\n",
    "# s3 uri where the trained model is located\n",
    "print(f\"s3 uri where the trained model is located: \\n{huggingface_estimator.model_data}\\n\")\n",
    "\n",
    "# latest training job name for this estimator\n",
    "print(f\"latest training job name for this estimator: \\n{huggingface_estimator.latest_training_job.name}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access the logs of the training job\n",
    "huggingface_estimator.sagemaker_session.logs_for_job(huggingface_estimator.latest_training_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download-fine-tuned-model-from-s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "OUTPUT_DIR = './output/'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "# 学習したモデルのダウンロード\n",
    "S3Downloader.download(\n",
    "    s3_uri=huggingface_estimator.model_data, # s3 uri where the trained model is located\n",
    "    local_path='.', # local path where *.targ.gz is saved\n",
    "    sagemaker_session=sess # sagemaker session used for training the model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# OUTPUT_DIRに解凍します\n",
    "\n",
    "!tar -zxvf model.tar.gz -C output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answering on Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained('./output')  \n",
    "tokenizer = AutoTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のセルは`./DDQA-1.0/RC-QA/DDQA-1.0_RC-QA_dev.json`からコピーしたものです"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = '実は先週、ＣＢＲ６００ＲＲで事故りました。たまにはＣＢＲにも乗らなきゃなーと思い久々にＣＢＲで出勤したところ、家から１０分ほど走ったところにある片側一車線の交差点で対向右折車と衝突してしまいました。自分が直進青信号で交差点へ進入したところで対向右折車線の車が突然右折を開始。とっさに急ブレーキはかけましたが、止まることはできずに右折車に衝突、自分は空中で一回転して左斜め数メートル先の路上へと飛ばされました。'\n",
    "question='何に乗っていて事故りましたか？'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#context = 'まぁ，何回か改正してるわけで，自転車を走らせる領域を変更しないって言うのは，怠慢っていうか責任逃れっていうか，道交法に携わってるヤツはみんな馬鹿なのか．大体の人はここまで極端な意見ではないだろうけど，自転車は歩道を走るほうが自然だとは考えているだろう．というのも， みんな自転車乗ってる時歩道を走るでしょ？自転車で歩道走ってても歩行者にそこまで危険な目に合わせないと考えているし，車道に出たら明らかに危険な目に合うと考えている．'\n",
    "#question='大体の人は自転車はどこを走るのが自然だと思っている？'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#context = '幸いけが人が出なくて良かったものの、タイヤの脱落事故が後を絶たない。先日も高速道路でトラックのタイヤがはずれ、中央分離帯を越え、反対車線を通行していた観光バスに直撃した。不幸にもバスを運転していた運転手さんがお亡くなりになった。もし、僕がこんな場面に遭遇していたら、この運転手さんのように、乗客の安全を考えて冷静に止まっただろうか？'\n",
    "#question = '後を絶たないのは何ですか？'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#context = '右折待ちの一般ドライバーの方は、直進車線からの右折タクシーに驚いて右折のタイミングを失ってしまい、更なる混雑を招いているようでした」と述べていました。２００４年８月６日付けには、ある女性が「道を譲っても挨拶をしない人が多い。特に女性の方。そのため意地悪ですが対向車のドライバーが女性だと譲りません。私はまだ人間が出来ていないので受け流すことが出来ません」ということを言っていましたが、その気持ち良く分かります。私は横断歩道の歩行者に対しては特別真面目で、歩行者がいるかどうかを常に注意して、いるときは必ず止まるよう心掛けています。それでも気付かずに止まることができなかったときは、「ああ、悪いことしちゃったな…」と、バックミラーを見ながら思います。'\n",
    "#question = '歩行者がいるかどうかを常に注意しているのは誰ですか？'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論\n",
    "inputs = tokenizer.encode_plus(question, context, add_special_tokens=True, return_tensors=\"pt\")\n",
    "input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "output = model(**inputs)\n",
    "answer_start = torch.argmax(output.start_logits)  \n",
    "answer_end = torch.argmax(output.end_logits) + 1 \n",
    "answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "\n",
    "# 結果\n",
    "print(\"質問: \"+question)\n",
    "print(\"回答: \"+answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
