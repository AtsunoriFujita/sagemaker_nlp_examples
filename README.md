# SageMaker NLP examples for Japanese

[Amazon SageMaker](https://aws.amazon.com/jp/sagemaker/)ã§å®Ÿè¡Œã§ãã‚‹ï¼ˆä¸»ã«æ—¥æœ¬èªã®ï¼‰è‡ªç„¶è¨€èªå‡¦ç†ã®ã‚µãƒ³ãƒ—ãƒ«é›†    
æ¨è«–å‘¨ã‚Šã¯SequenceClassificationã®ä¸‹ã«ã¾ã¨ã¾ã£ã¦ã„ã¾ã™ï¼ˆSageMakerã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã€ãƒãƒƒãƒå¤‰æ›ã‚¸ãƒ§ãƒ–ã€TorchServeã€Lambdaï¼‰ã€‚

## Examples
- SequenceClassification
  - AmazonSageMaker, ğŸ¤— Transformers, æ—¥æœ¬èªBERT, Amazonãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
- TokenClassification
  - AmazonSageMaker, ğŸ¤— Transformers, æ—¥æœ¬èªBERT, Wikipediaã‚’ç”¨ã„ãŸæ—¥æœ¬èªã®å›ºæœ‰è¡¨ç¾æŠ½å‡ºãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
- QuestionAnswering
  - AmazonSageMaker, ğŸ¤— Transformers, æ—¥æœ¬èªBERT, é‹è»¢ãƒ‰ãƒ¡ã‚¤ãƒ³QAãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
- Summarization
  - AmazonSageMaker, ğŸ¤— Transformers, æ—¥æœ¬èªT5, wikiHowæ—¥æœ¬èªè¦ç´„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
- GPT2 Fine-Tuning
  - AmazonSageMaker, ğŸ¤— Transformers, æ—¥æœ¬èªGPT2, wikiHowæ—¥æœ¬èªè¦ç´„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
- BlazingText
  - AmazonSageMaker, built-in BlazingText(æ•™å¸«ãªã—, Word2vec), ja.text8
  - AmazonSageMaker, built-in BlazingText(æ•™å¸«ã‚ã‚Š, ãƒ†ã‚­ã‚¹ãƒˆåˆ†é¡), Amazonãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
- LatentDirichletAllocation(LDA)
  - AmazonSageMaker, built-in LDA, livedoorãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‘ã‚¹
- AmazonCoprehend_tutorial
  - AmazonCoprehend, EntityæŠ½å‡º, KeyPhraseæŠ½å‡º, Sentimentåˆ†æ, Amazonãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

Others?    
Stay tuned!
