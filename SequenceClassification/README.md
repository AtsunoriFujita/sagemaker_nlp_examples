# SequenceClassification

![SequenceClassification](https://user-images.githubusercontent.com/40932835/122213598-14b1e400-cee4-11eb-8733-73f1ae579f84.png)

â†‘ã®ç”»åƒã¯[ã“ã“](https://d2l.ai/chapter_natural-language-processing-applications/finetuning-bert.html)ã‹ã‚‰

## pytorch_training
- SageMaker HuggingFaceã‚³ãƒ³ãƒ†ãƒŠã‚’ä½¿ç”¨ã—ãŸPyTorchã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¸ãƒ§ãƒ–
  - HuggingFaceã®[SageMaker example](https://github.com/huggingface/notebooks/tree/master/sagemaker)ã‹ã‚‰01_getting_started_pytorch, 05_spot_instances, 06_sagemaker_metricsã‚’å‚ç…§
- Amazonã®å•†å“ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ãŸäºŒå€¤åˆ†é¡
- [æ±åŒ—å¤§å­¦ã®æ—¥æœ¬èªBERT](https://github.com/cl-tohoku/bert-japanese)ã‚’ä½¿ç”¨ã—ãŸFine-Tuning

## pytorch_inference
- SageMaker HuggingFaceã‚³ãƒ³ãƒ†ãƒŠã‚’ä½¿ç”¨ã—ãŸTransformersãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ—ãƒ­ã‚¤
  - HuggingFaceã®[SageMaker example](https://github.com/huggingface/notebooks/tree/master/sagemaker)ã®10_deploy_model_from_s3, 11_deploy_model_from_hf_hubã‚’å‚ç…§ã—ã€æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ã¸å¯¾å¿œã§ãã‚‹ã‚ˆã†å¤‰æ›´ã—ã¦ã„ã¾ã™ã€‚
- HuggingFaceã®Transformersã§å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’SageMakerä¸Šã¸ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹æ–¹æ³•ã¨ã€[ğŸ¤— Hub](https://huggingface.co/models)ã®ãƒ¢ãƒ‡ãƒ«ã‚’SageMakerä¸Šã¸ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹æ–¹æ³•ã®2ç¨®é¡ã‚’æ‰±ã£ã¦ã„ã¾ã™ã€‚

```python
data = {"inputs": 'ãƒãƒ¯ã‚¤ã‚¢ãƒ³ã®å¿ƒå’Œã‚€éŸ³æ¥½ã®ä¸­ã€ã¡ã‚‡ã£ã¨ã‚·ãƒªã‚¢ã‚¹ãªãƒ‰ãƒ©ãƒãŒå±•é–‹ã—ã¦ã„ãã¾ã™ã€‚éŸ³æ¥½ã®åŠ›ã£ã¦ã™ã”ã„ãªã€ã£ã¦æ€ã„ã¾ã—ãŸã€‚'}
predictor.predict(data)
# [{'label': 'LABEL_1', 'score': 0.9968476295471191}]
```

## pytorch_inference_on_torchserve
- [TorchServe](https://github.com/pytorch/serve)ã®æ¨è«–ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’SageMakerã®Modelã‚¯ãƒ©ã‚¹ã§ãƒ‡ãƒ—ãƒ­ã‚¤    
- `pytorch_training`ã§å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨

```python
payload ='ãƒãƒ¯ã‚¤ã‚¢ãƒ³ã®å¿ƒå’Œã‚€éŸ³æ¥½ã®ä¸­ã€ã¡ã‚‡ã£ã¨ã‚·ãƒªã‚¢ã‚¹ãªãƒ‰ãƒ©ãƒãŒå±•é–‹ã—ã¦ã„ãã¾ã™ã€‚éŸ³æ¥½ã®åŠ›ã£ã¦ã™ã”ã„ãªã€ã£ã¦æ€ã„ã¾ã—ãŸã€‚'
predictor.predict(data=payload).decode(encoding='utf-8')
# 'Positive'
```

### Reference
- [The Partnership: Amazon SageMaker and Hugging Face](https://huggingface.co/blog/the-partnership-amazon-sagemaker-and-hugging-face)
- [Run training on Amazon SageMaker](https://huggingface.co/transformers/sagemaker.html#access-trained-model)
- [cl-tohoku/bert-japanese](https://github.com/cl-tohoku/bert-japanese)
- [Deploy Hugging Face models easily with Amazon SageMaker](https://huggingface.co/blog/deploy-hugging-face-models-easily-with-amazon-sagemaker)
- [sagemaker-huggingface-inference-toolkit](https://github.com/aws/sagemaker-huggingface-inference-toolkit)
- [TorchServeã‚’ä½¿ç”¨ã—ãŸå¤§è¦æ¨¡ãªæ¨è«–ã®ãŸã‚ã®PyTorchãƒ¢ãƒ‡ãƒ«ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹](https://aws.amazon.com/jp/blogs/news/deploying-pytorch-models-for-inference-at-scale-using-torchserve/)    
- [torchserve-examples](https://github.com/shashankprasanna/torchserve-examples)
- [Deploy FastAI Trained PyTorch Model in TorchServe and Host in Amazon SageMaker Inference Endpoint](https://github.com/aws-samples/amazon-sagemaker-endpoint-deployment-of-fastai-model-with-torchserve)
