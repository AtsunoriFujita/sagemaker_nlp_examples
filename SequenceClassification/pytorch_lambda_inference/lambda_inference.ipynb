{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "947947f9",
   "metadata": {},
   "source": [
    "# ğŸ¤— Transformers on AWS Lambda container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5a0c36",
   "metadata": {},
   "source": [
    "å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã¯ã‚³ãƒ³ãƒ†ãƒŠã‚’ä½¿ã£ã¦AWS Lambdaä¸Šã§æ¨è«–ã™ã‚‹ã“ã¨ã‚‚å¯èƒ½ã§ã™ã€‚ã“ã“ã§ã¯ãã®æ–¹æ³•ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚\n",
    "\n",
    "**ã“ã®Notebookã§ã¯ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã¯è¡Œã‚ãšã€HuggingFace ğŸ¤— [Hub](https://huggingface.co/models)ã«ã‚ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8101b784",
   "metadata": {},
   "source": [
    "## IAM Role\n",
    "\n",
    "Note: IAMãƒ­ãƒ¼ãƒ«ã«ä»¥ä¸‹ã®æ¨©é™ãŒã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„:\n",
    "\n",
    "- AmazonSageMakerFullAccess\n",
    "- AmazonS3FullAccess\n",
    "- AmazonEC2ContainerRegistryFullAccess\n",
    "- AWSLambda_FullAccess\n",
    "\n",
    "ECRã¨Lambdaã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã«ã€`AmazonEC2ContainerRegistryFullAccess`ã¨`AWSLambda_FullAccess`ãŒå¿…è¦ã«ãªã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff528ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install \"sagemaker>=2.48.0\" \"torch>=1.7.1\" \"transformers[ja]==4.6.0\" \"datasets==1.11\" --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4654a839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "OUTPUT_DIR = './lambda-docker/model'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f5f401",
   "metadata": {},
   "source": [
    "ã‚³ãƒ³ãƒ†ãƒŠãƒ‡ãƒ—ãƒ­ã‚¤ã®ãŸã‚ã«Modelã¨Tokenizerã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ï¼ˆã‚ã‚‰ã‹ã˜ã‚ä½œæˆã—ãŸModelã¨Tokenizerã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯`OUTPUT_DIR`ã«é…ç½®ã—ã¦ãã ã•ã„ï¼‰ã€‚    \n",
    "ã“ã®ã‚µãƒ³ãƒ—ãƒ«ã§ã¯ã€ğŸ¤— Hubã‹ã‚‰ https://huggingface.co/abhishek/autonlp-japanese-sentiment-59363 ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe62e880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/philschmid/serverless-bert-huggingface-aws-lambda-docker/blob/main/get_model.py\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "def get_model(model):\n",
    "    \"\"\"Loads model from Hugginface model hub\"\"\"\n",
    "    try:\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model)\n",
    "        model.save_pretrained(OUTPUT_DIR)\n",
    "    except Exception as e:\n",
    "        raise(e)\n",
    "\n",
    "def get_tokenizer(tokenizer):\n",
    "    \"\"\"Loads tokenizer from Hugginface model hub\"\"\"\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(tokenizer)\n",
    "        tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "    except Exception as e:\n",
    "        raise(e)\n",
    "\n",
    "get_model('abhishek/autonlp-japanese-sentiment-59363')\n",
    "get_tokenizer('abhishek/autonlp-japanese-sentiment-59363')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b89f55",
   "metadata": {},
   "source": [
    "ä»¥ä¸‹ã®ã‚»ãƒ«ã¯Lambdaã§å®Ÿè¡Œã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’å®šç¾©ã—ã¦æ›¸ãå‡ºã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a542956",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./lambda-docker/handler.py\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig\n",
    "\n",
    "\n",
    "def encode(tokenizer, inputs):\n",
    "    \"\"\"encodes the question and context with a given tokenizer\"\"\"\n",
    "    encoded = tokenizer.encode_plus(inputs)\n",
    "    return encoded[\"input_ids\"], encoded[\"attention_mask\"]\n",
    "\n",
    "\n",
    "def serverless_pipeline(model_path='./model'):\n",
    "    \"\"\"Initializes the model and tokenzier and returns a predict function that ca be used as pipeline\"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "    labels = ['LABEL_0', 'LABEL_1']\n",
    "    def predict(inputs):\n",
    "        \"\"\"predicts the answer on an given question and context. Uses encode and decode method from above\"\"\"\n",
    "        input_ids, attention_mask = encode(tokenizer, inputs)\n",
    "        outputs = model(torch.tensor([input_ids]), attention_mask=torch.tensor([attention_mask]))[0]\n",
    "        prob = F.softmax(outputs, dim=1).detach().numpy().astype(np.float64).max()\n",
    "        return {'label': labels[torch.argmax(outputs)], 'score': prob}\n",
    "    return predict\n",
    "\n",
    "\n",
    "# initializes the pipeline\n",
    "sequence_classification_pipeline = serverless_pipeline()\n",
    "\n",
    "\n",
    "def handler(event, context):\n",
    "    try:\n",
    "        print(event)\n",
    "        print(context)\n",
    "        # loads the incoming event into a dictonary\n",
    "        body = json.loads(event['body'])\n",
    "        # uses the pipeline to predict the answer\n",
    "        output = sequence_classification_pipeline(inputs=body['inputs'])\n",
    "        print(output)\n",
    "        return {\n",
    "            \"statusCode\": 200,\n",
    "            \"headers\": {\n",
    "                'Content-Type': 'application/json',\n",
    "                'Access-Control-Allow-Origin': '*',\n",
    "                \"Access-Control-Allow-Credentials\": True\n",
    "            },\n",
    "            \"body\": json.dumps(output)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(repr(e))\n",
    "        return {\n",
    "            \"statusCode\": 500,\n",
    "            \"headers\": {\n",
    "                'Content-Type': 'application/json',\n",
    "                'Access-Control-Allow-Origin': '*',\n",
    "                \"Access-Control-Allow-Credentials\": True\n",
    "            },\n",
    "            \"body\": json.dumps({\"error\": repr(e)})\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb28ca6f",
   "metadata": {},
   "source": [
    "## Create an Amazon ECR registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94d7e7a",
   "metadata": {},
   "source": [
    "`lambda-docker`ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã«ã‚ã‚‹`requirements.txt`ã¨`dockerfile`ã¨`handler.py`ã€Modelã€Tokenizerã‚’ECRã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43701836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "sess = boto3.Session()\n",
    "\n",
    "registry_name = 'huggingface-lambda-classification'\n",
    "account = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = sess.region_name\n",
    "\n",
    "!aws ecr create-repository --repository-name {registry_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bce69cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "image_label = 'v1'\n",
    "image = f'{account}.dkr.ecr.{region}.amazonaws.com/{registry_name}:{image_label}'\n",
    "\n",
    "%cd lambda-docker\n",
    "!docker build -t {registry_name}:{image_label} .\n",
    "!$(aws ecr get-login --no-include-email --region {region})\n",
    "!docker tag {registry_name}:{image_label} {image}\n",
    "!docker push {image}\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66d2e53",
   "metadata": {},
   "source": [
    "## Create a Lambda Function\n",
    "\n",
    "[IAM ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã§ã®å®Ÿè¡Œãƒ­ãƒ¼ãƒ«ã®ä½œæˆ](https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/lambda-intro-execution-role.html)ã‚’å‚ç…§ã—ã¦ã€\n",
    "IAM ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã§å®Ÿè¡Œãƒ­ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "1. IAM ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã® [Roles (ãƒ­ãƒ¼ãƒ«)] ãƒšãƒ¼ã‚¸ã‚’é–‹ãã¾ã™ã€‚\n",
    "2. [ãƒ­ãƒ¼ãƒ«ã®ä½œæˆ] ã‚’é¸æŠã—ã¾ã™ã€‚\n",
    "3. [ä¸€èˆ¬çš„ãªãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹] ã§ã€[Lambda] ã‚’é¸æŠã—ã¾ã™ã€‚\n",
    "4. [Next: Permissions (æ¬¡ã¸: ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯)] ã‚’é¸æŠã—ã¾ã™ã€‚\n",
    "5. [ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯ãƒãƒªã‚·ãƒ¼ã®ã‚¢ã‚¿ãƒƒãƒ] ã§ã€[AWSLambdaBasicExecutionRole] ãŠã‚ˆã³ [AWSXRayDaemonWriteAccess] AWS ç®¡ç†ãƒãƒªã‚·ãƒ¼ã‚’é¸æŠã—ã¾ã™ã€‚\n",
    "6. [æ¬¡ã¸: ã‚¿ã‚°] ã‚’é¸æŠã—ã¾ã™ã€‚\n",
    "7. [Next: Review] ã‚’é¸æŠã—ã¾ã™ã€‚\n",
    "8. [ãƒ­ãƒ¼ãƒ«å] ã«ã€Œlambda-roleã€ã¨å…¥åŠ›ã—ã¾ã™ï¼ˆãƒ­ãƒ¼ãƒ«åã¯ä»»æ„ã®åå‰ã§æ§‹ã„ã¾ã›ã‚“ï¼‰ã€‚\n",
    "9. [ãƒ­ãƒ¼ãƒ«ã®ä½œæˆ] ã‚’é¸æŠã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d600cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = 'YOUR-LAMBDA-ROLE-ARN'\n",
    "fname = 'bert-lambda-classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722bc990",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdac = boto3.client('lambda')\n",
    "\n",
    "dic = {\n",
    "    'FunctionName': fname,\n",
    "    'Role': role,\n",
    "    'Code':{'ImageUri': image},\n",
    "    'Timeout': 60,\n",
    "    'MemorySize': 5120,\n",
    "    'PackageType':'Image'   #add this parameter\n",
    "}\n",
    "\n",
    "lambdac.create_function(**dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011ccfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆã§è©¦ã—ã«æ¨è«–ã—ã¦ã¿ã¾ã—ã‚‡ã†\n",
    "payload = {\n",
    "  \"body\": '{\"inputs\": \"ãƒãƒ¯ã‚¤ã‚¢ãƒ³ã®å¿ƒå’Œã‚€éŸ³æ¥½ã®ä¸­ã€ã¡ã‚‡ã£ã¨ã‚·ãƒªã‚¢ã‚¹ãªãƒ‰ãƒ©ãƒãŒå±•é–‹ã—ã¦ã„ãã¾ã™ã€‚éŸ³æ¥½ã®åŠ›ã£ã¦ã™ã”ã„ãªã€ã£ã¦æ€ã„ã¾ã—ãŸã€‚\"}'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4421fe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambdaé–¢æ•°ã®ä½œæˆãŒå®Œäº†ã—ã¦ã„ãªã„å ´åˆã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™\n",
    "# åˆå›ã®å®Ÿè¡Œã«ã¯å°‘ã—æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™\n",
    "import json\n",
    "\n",
    "output = lambdac.invoke(\n",
    "    FunctionName=fname,\n",
    "    Payload= json.dumps(payload),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce17347",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(output['Payload'].read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fccc51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c281c456f1b8161c8906f4af2c08ed2c40c50136979eaae69688b01f70e9f4a9"
  },
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
