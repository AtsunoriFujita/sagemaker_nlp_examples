{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70903743",
   "metadata": {},
   "source": [
    "# Huggingface SageMaker-SDK - T5 Summarization example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddee973e",
   "metadata": {},
   "source": [
    "1. [Introduction](#Introduction)  \n",
    "2. [Development Environment and Permissions](#Development-Environment-and-Permissions)\n",
    "    1. [Installation](#Installation)  \n",
    "    2. [Permissions](#Permissions)\n",
    "    3. [Uploading data to sagemaker_session_bucket](#Uploading-data-to-sagemaker_session_bucket)  \n",
    "3. [Fine-tuning & starting Sagemaker Training Job](#Fine-tuning-\\&-starting-Sagemaker-Training-Job)  \n",
    "    1. [Creating an Estimator and start a training job](#Creating-an-Estimator-and-start-a-training-job)  \n",
    "    2. [Download fine-tuned model from s3](#Download-fine-tuned-model-from-s3)\n",
    "    3. [Summarization on Local](#Summarization-on-Local)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cb5c9a",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "このnotebookはHuggingFaceの[run_summarization.py](https://github.com/huggingface/transformers/blob/master/examples/pytorch/summarization/run_summarization.py)を日本語データで実行します。    \n",
    "\n",
    "**51行目の`check_min_version(\"4.10.0.dev0\")`をコメントアウトした以外はSageMakerで実行するために変更を加えた部分はありません**\n",
    "\n",
    "事前訓練モデルには[sonoisa/t5-base-japanese](https://huggingface.co/sonoisa/t5-base-japanese)を使用し、データは[wikiHow日本語要約データセット](https://github.com/Katsumata420/wikihow_japanese)を使用します。    \n",
    "\n",
    "このデモでは、AmazonSageMakerのHuggingFace Estimatorを使用してSageMakerのトレーニングジョブを実行します。    \n",
    "\n",
    "_**NOTE: このデモは、SagemakerNotebookインスタンスで動作検証しています**_    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29565e8c",
   "metadata": {},
   "source": [
    "# Development Environment and Permissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf5f4a3",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "このNotebookはSageMakerの`conda_pytorch_p36`カーネルを利用しています。    \n",
    "\n",
    "**_Note: このnotebook上で推論テストを行う場合、（バージョンが古い場合は）pytorchのバージョンアップが必要になります。_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89027b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install --upgrade torch\n",
    "!pip install \"sagemaker>=2.48.1\" \"transformers==4.9.2\" \"datasets[s3]>=1.8.0\" --upgrade\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4fe665",
   "metadata": {},
   "source": [
    "## Permissions\n",
    "\n",
    "ローカル環境でSagemakerを使用する場合はSagemakerに必要な権限を持つIAMロールにアクセスする必要があります。[こちら](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html)を参照してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553cb901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f765b1b0",
   "metadata": {},
   "source": [
    "# データの準備\n",
    "\n",
    "事前に`create_wikihow_dataset.ipynb`を実行してwikiHow日本語要約データセットを用意してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b415e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb703f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json('./wikihow_japanese/data/output/train.jsonl', orient='records', lines=True)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad953e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = pd.read_json('./wikihow_japanese/data/output/dev.jsonl', orient='records', lines=True)\n",
    "dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b883978",
   "metadata": {},
   "source": [
    "[run_summarization.py](https://github.com/huggingface/transformers/blob/master/examples/pytorch/summarization/run_summarization.py)の実行にあたり、データを少し修正します。    \n",
    "データのフォーマットは`csv`もしくは`json`で以下のように「原文（Text）」と「要約（summary）」を含む必要があります。    \n",
    "\n",
    "```\n",
    "text,summary\n",
    "\"I'm sitting here in a boring room. It's just another rainy Sunday afternoon. I'm wasting my time I got nothing to do. I'm hanging around I'm waiting for you. But nothing ever happens. And I wonder\",\"I'm sitting in a room where I'm waiting for something to happen\"\n",
    "\"I see trees so green, red roses too. I see them bloom for me and you. And I think to myself what a wonderful world. I see skies so blue and clouds so white. The bright blessed day, the dark sacred night. And I think to myself what a wonderful world.\",\"I'm a gardener and I'm a big fan of flowers.\"\n",
    "\"Christmas time is here. Happiness and cheer. Fun for all that children call. Their favorite time of the year. Snowflakes in the air. Carols everywhere. Olden times and ancient rhymes. Of love and dreams to share\",\"It's that time of year again.\"\n",
    "```\n",
    "\n",
    "```\n",
    "{\"text\": \"I'm sitting here in a boring room. It's just another rainy Sunday afternoon. I'm wasting my time I got nothing to do. I'm hanging around I'm waiting for you. But nothing ever happens. And I wonder\", \"summary\": \"I'm sitting in a room where I'm waiting for something to happen\"}\n",
    "{\"text\": \"I see trees so green, red roses too. I see them bloom for me and you. And I think to myself what a wonderful world. I see skies so blue and clouds so white. The bright blessed day, the dark sacred night. And I think to myself what a wonderful world.\", \"summary\": \"I'm a gardener and I'm a big fan of flowers.\"}\n",
    "{\"text\": \"Christmas time is here. Happiness and cheer. Fun for all that children call. Their favorite time of the year. Snowflakes in the air. Carols everywhere. Olden times and ancient rhymes. Of love and dreams to share\", \"summary\": \"It's that time of year again.\"}\n",
    "```\n",
    "\n",
    "詳細は[こちら](https://github.com/huggingface/transformers/tree/master/examples/pytorch/summarization)にあります。    \n",
    "ここでは`jsonl`のファイルを`csv`に変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cf09fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train.csv', index=False)\n",
    "dev.to_csv('dev.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816d840c",
   "metadata": {},
   "source": [
    "## Uploading data to `sagemaker_session_bucket`\n",
    "\n",
    "S3へデータをアップロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98038e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_prefix = 'samples/datasets/wikihow_csv'\n",
    "\n",
    "input_train = sess.upload_data(\n",
    "    path='train.csv', \n",
    "    key_prefix=f'{s3_prefix}/train'\n",
    ")\n",
    "\n",
    "input_validation = sess.upload_data(\n",
    "    path='dev.csv', \n",
    "    key_prefix=f'{s3_prefix}/valid'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e0900c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データのUpload path\n",
    "\n",
    "print(input_train)\n",
    "print(input_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5876e54",
   "metadata": {},
   "source": [
    "# Fine-tuning & starting Sagemaker Training Job\n",
    "\n",
    "`HuggingFace`のトレーニングジョブを作成するためには`HuggingFace` Estimatorが必要になります。    \n",
    "Estimatorは、エンドツーエンドのAmazonSageMakerトレーニングおよびデプロイタスクを処理します。 Estimatorで、どのFine-tuningスクリプトを`entry_point`として使用するか、どの`instance_type`を使用するか、どの`hyperparameters`を渡すかなどを定義します。\n",
    "\n",
    "\n",
    "```python\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point='train.py',\n",
    "    source_dir='./scripts',\n",
    "    base_job_name='huggingface-sdk-extension',\n",
    "    instance_type='ml.p3.2xlarge',\n",
    "    instance_count=1,\n",
    "    transformers_version='4.4',\n",
    "    pytorch_version='1.6',\n",
    "    py_version='py36',\n",
    "    role=role,\n",
    "    hyperparameters={\n",
    "        'epochs': 1,\n",
    "        'train_batch_size': 32,\n",
    "        'model_name':'distilbert-base-uncased'\n",
    "    }\n",
    ")\n",
    "```\n",
    "\n",
    "SageMakerトレーニングジョブを作成すると、SageMakerは`huggingface`コンテナを実行するために必要なec2インスタンスの起動と管理を行います。    \n",
    "Fine-tuningスクリプト`train.py`をアップロードし、`sagemaker_session_bucket`からコンテナ内の`/opt/ml/input/data`にデータをダウンロードして、トレーニングジョブを実行します。\n",
    "\n",
    "\n",
    "```python\n",
    "/opt/conda/bin/python train.py --epochs 1 --model_name distilbert-base-uncased --train_batch_size 32\n",
    "```\n",
    "\n",
    "`HuggingFace estimator`で定義した`hyperparameters`は、名前付き引数として渡されます。\n",
    "\n",
    "またSagemakerは、次のようなさまざまな環境変数を通じて、トレーニング環境に関する有用なプロパティを提供しています。\n",
    "\n",
    "* `SM_MODEL_DIR`：トレーニングジョブがモデルアーティファクトを書き込むパスを表す文字列。トレーニング後、このディレクトリのアーティファクトはモデルホスティングのためにS3にアップロードされます。\n",
    "\n",
    "* `SM_NUM_GPUS`：ホストで使用可能なGPUの数を表す整数。\n",
    "\n",
    "* `SM_CHANNEL_XXXX`：指定されたチャネルの入力データを含むディレクトリへのパスを表す文字列。たとえば、HuggingFace estimatorのfit呼び出しで`train`と`test`という名前の2つの入力チャネルを指定すると、環境変数`SM_CHANNEL_TRAIN`と`SM_CHANNEL_TEST`が設定されます。\n",
    "\n",
    "このトレーニングジョブをローカル環境で実行するには、`instance_type='local'`、GPUの場合は`instance_type='local_gpu'`で定義できます（GPUの場合は追加で設定が必要になります[SageMakerのドキュメント](https://sagemaker.readthedocs.io/en/stable/overview.html#local-mode)を参照してください）。    \n",
    "**_Note：これはSageMaker Studio内では機能しません_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23b5df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements.txtはトレーニングジョブの実行前に実行されます（コンテナにライブラリを追加する際に使用します）\n",
    "# ファイルはここを参照しています。https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/requirements.txt\n",
    "# 1点異なる部分は transformers >= 4.8.0 でHuggingFaceコンテナのバージョンが古く本家に追いついていないため、バージョンアップを行なっています。\n",
    "!pygmentize ./scripts/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66aa58b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーニングジョブで実行されるコード\n",
    "!pygmentize ./scripts/run_summarization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ddf75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters={\n",
    "    'model_name_or_path':'sonoisa/t5-base-japanese',\n",
    "    'train_file': '/opt/ml/input/data/train/train.csv',\n",
    "    'validation_file': '/opt/ml/input/data/validation/dev.csv',\n",
    "    'text_column': 'src',\n",
    "    'summary_column': 'tgt',\n",
    "    'max_source_length': 1024,\n",
    "    'max_target_length': 128,\n",
    "    'do_train': 'True',\n",
    "    'do_eval': 'True',\n",
    "    'predict_with_generate': 'True',\n",
    "    'num_train_epochs': 5,\n",
    "    'per_device_train_batch_size': 2,\n",
    "    'per_device_eval_batch_size': 2,\n",
    "    'use_fast_tokenizer': 'False',\n",
    "    'save_steps': 500,\n",
    "    'save_total_limit': 1,\n",
    "    'output_dir':'/opt/ml/model',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd994580",
   "metadata": {},
   "source": [
    "## Creating an Estimator and start a training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2a1d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    role=role,\n",
    "    entry_point='run_summarization.py',\n",
    "    source_dir='./scripts',\n",
    "    instance_type='ml.p3.8xlarge',\n",
    "    instance_count=1,\n",
    "    volume_size=200,\n",
    "    transformers_version='4.6',\n",
    "    pytorch_version='1.7',\n",
    "    py_version='py36',\n",
    "    hyperparameters=hyperparameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5422cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting the train job with our uploaded datasets as input\n",
    "huggingface_estimator.fit({'train': input_train, 'validation': input_validation})\n",
    "\n",
    "# ml.p3.8xlarge, 5 epochでの実行時間の目安\n",
    "# Training seconds: 2894\n",
    "# Billable seconds: 2894"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a662de4",
   "metadata": {},
   "source": [
    "## Download-fine-tuned-model-from-s3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2d8adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "OUTPUT_DIR = './output/'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5611ae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "# 学習したモデルのダウンロード\n",
    "S3Downloader.download(\n",
    "    s3_uri=huggingface_estimator.model_data, # s3 uri where the trained model is located\n",
    "    local_path='.', # local path where *.targ.gz is saved\n",
    "    sagemaker_session=sess # sagemaker session used for training the model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d718da08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT_DIRに解凍します\n",
    "\n",
    "!tar -zxvf model.tar.gz -C output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e547475",
   "metadata": {},
   "source": [
    "## Summarization on Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c2120b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('output/')    \n",
    "tokenizer = AutoTokenizer.from_pretrained('sonoisa/t5-base-japanese') \n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eed100b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = dev.src[1]\n",
    "inputs = tokenizer.encode(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "\n",
    "print('='*5,'原文', '='*5)\n",
    "print(text)\n",
    "print('-'*5, '要約', '-'*5)\n",
    "\n",
    "with torch.no_grad():\n",
    "    summary_ids = model.generate(inputs, max_length=1024, do_sample=False, num_beams=1)\n",
    "    summary = tokenizer.decode(summary_ids[0])\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0b49c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
